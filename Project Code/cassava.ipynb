{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAoQozqB2-9X"
      },
      "source": [
        "# **Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF7d_Pdx3CR-"
      },
      "outputs": [],
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0qP28lD3ECZ"
      },
      "source": [
        "# **Mount Google Drive and Define Paths and Create Folders**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEh0GA493MFP",
        "outputId": "69001114-a315-4b96-bebe-b7f047d2df03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Output folder created at: /content/drive/MyDrive/Dataset/train/augmented_images\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 3: Define paths for input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/Dataset/train/train_data\"  # Folder containing original images\n",
        "csv_path = \"/content/drive/MyDrive/Dataset/train/other/train.csv\"  # Path to the CSV file\n",
        "output_folder = \"/content/drive/MyDrive/Dataset/train/augmented_images\"  # Folder to save augmented images\n",
        "\n",
        "# Create the output folder if it doesn't exist\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "print(f\"Output folder created at: {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CaP8XEu3luF"
      },
      "source": [
        "# **Load CSV File and Add Class Names**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xBMR0Nj3nUu",
        "outputId": "554b9943-f806-411e-a3a2-9f3807acc851"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file loaded successfully. First few rows:\n",
            "         image_id  label\n",
            "0  1000015157.jpg      0\n",
            "1  1000201771.jpg      3\n",
            "2   100042118.jpg      1\n",
            "3  1000723321.jpg      1\n",
            "4  1000812911.jpg      3\n",
            "DataFrame with class names added:\n",
            "         image_id  label                           class_name\n",
            "0  1000015157.jpg      0       Cassava Bacterial Blight (CBB)\n",
            "1  1000201771.jpg      3         Cassava Mosaic Disease (CMD)\n",
            "2   100042118.jpg      1  Cassava Brown Streak Disease (CBSD)\n",
            "3  1000723321.jpg      1  Cassava Brown Streak Disease (CBSD)\n",
            "4  1000812911.jpg      3         Cassava Mosaic Disease (CMD)\n"
          ]
        }
      ],
      "source": [
        "# Step 5: Load the CSV file containing image IDs and labels\n",
        "df = pd.read_csv(csv_folder)\n",
        "print(\"CSV file loaded successfully. First few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 6: Define a mapping for labels to class names\n",
        "label_mapping = {\n",
        "    0: \"Cassava Bacterial Blight (CBB)\",\n",
        "    1: \"Cassava Brown Streak Disease (CBSD)\",\n",
        "    2: \"Cassava Green Mottle (CGM)\",\n",
        "    3: \"Cassava Mosaic Disease (CMD)\",\n",
        "    4: \"Healthy\"\n",
        "}\n",
        "\n",
        "# Step 7: Add a new column to the DataFrame for class names\n",
        "df['class_name'] = df['label'].map(label_mapping)\n",
        "print(\"DataFrame with class names added:\")\n",
        "print(df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP4CLH8Y3pT_"
      },
      "source": [
        "# **Split Dataset into Training and Validation Sets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZdLnnSO3sy6",
        "outputId": "01686db9-1ed9-434e-9d77-eaf5d38a36c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training samples: 17117\n",
            "Validation samples: 4280\n"
          ]
        }
      ],
      "source": [
        "# Step 8: Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(\"Training samples:\", len(train_df))\n",
        "print(\"Validation samples:\", len(val_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYn-SjLg3vBz"
      },
      "source": [
        "# **Define Image Dimensions and Data Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VU39Xw8c3zBJ"
      },
      "outputs": [],
      "source": [
        "# Step 9: Define image dimensions and batch size\n",
        "img_height, img_width = 150, 150  # Resize images to 150x150 pixels\n",
        "batch_size = 32  # Number of images processed in each batch\n",
        "\n",
        "# Step 10: Set up data augmentation for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally by 20%\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically by 20%\n",
        "    shear_range=0.2,  # Apply shear transformations\n",
        "    zoom_range=0.2,  # Randomly zoom images by 20%\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels with the nearest value\n",
        ")\n",
        "\n",
        "# Step 11: Only rescale validation data (no augmentation)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4k0i1Qtj3zxg"
      },
      "source": [
        "# **Create Data Generators**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKu6xhT133iu",
        "outputId": "ee4e91c8-3b11-4d3c-e6d7-b7d2e5b41b2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 13484 validated image filenames.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3633 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3414 validated image filenames.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 866 invalid image filename(s) in x_col=\"image_id\". These filename(s) will be ignored.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Step 12: Create a training data generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,  # Training DataFrame\n",
        "    directory=input_folder,  # Folder containing images\n",
        "    x_col='image_id',  # Column with image filenames\n",
        "    y_col='label',  # Column with integer labels\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    class_mode='raw'  # Use 'raw' for integer labels\n",
        ")\n",
        "\n",
        "# Step 13: Create a validation data generator\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,  # Validation DataFrame\n",
        "    directory=input_folder,  # Folder containing images\n",
        "    x_col='image_id',  # Column with image filenames\n",
        "    y_col='label',  # Column with integer labels\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    class_mode='raw',  # Use 'raw' for integer labels\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GS6CjfP834cm"
      },
      "source": [
        "# **Visualize and Save Augmented Images**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "3Imz1Gwf38GH",
        "outputId": "695d6712-aafb-4f58-b435-17d55bb2456b"
      },
      "outputs": [],
      "source": [
        "# Step 14: Function to visualize and save 8 types of augmented images in separate folders\n",
        "def visualize_and_save_augmented_images(generator, save_dir, num_images=50):\n",
        "    # Get the first batch of images and labels\n",
        "    images, labels = next(generator)\n",
        "\n",
        "    # Create a subfolder for each image and save the augmented images\n",
        "    for i in range(num_images):\n",
        "        image_folder = os.path.join(save_dir, f'augmented_image_{i + 1}')  # Create folder for each image\n",
        "        os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "        # Save the original image\n",
        "        img = array_to_img(images[i])  # Convert array to image\n",
        "        img.save(os.path.join(image_folder, f'original_image_{i + 1}.jpg'))  # Save original image\n",
        "\n",
        "        # Display the original image\n",
        "        plt.figure()\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(f'Original Image - Label: {labels[i]}')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "        # Generate and save 8 augmented images\n",
        "        for j in range(8):\n",
        "            # Apply random transformation using the ImageDataGenerator\n",
        "            augmented_image = train_datagen.random_transform(images[i])  # Apply random transformation\n",
        "            augmented_img = array_to_img(augmented_image)  # Convert array to image\n",
        "            augmented_img.save(os.path.join(image_folder, f'augmented_image_{i + 1}_type_{j + 1}.jpg'))  # Save augmented image\n",
        "\n",
        "            # Display the augmented image\n",
        "            plt.figure()\n",
        "            plt.imshow(augmented_image)\n",
        "            plt.title(f'Augmented Image {j + 1} - Label: {labels[i]}')\n",
        "            plt.axis('off')\n",
        "            plt.show()\n",
        "\n",
        "# Step 15: Call the function to visualize and save augmented images\n",
        "visualize_and_save_augmented_images(train_generator, output_folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm57tKwI3_zT"
      },
      "source": [
        "# **Define and Compile the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INHDdgJw4CYP"
      },
      "outputs": [],
      "source": [
        "# Step 16: Define the CNN model architecture\n",
        "num_classes = len(label_mapping)  # Number of unique classes\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),  # First convolutional layer\n",
        "    layers.MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),  # Second convolutional layer\n",
        "    layers.MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),  # Third convolutional layer\n",
        "    layers.MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    layers.Flatten(),  # Flatten the output\n",
        "    layers.Dense(512, activation='relu'),  # Fully connected layer\n",
        "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    layers.Dense(num_classes, activation='softmax')  # Output layer with softmax activation\n",
        "])\n",
        "\n",
        "# Step 17: Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',  # Optimizer\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for integer labels\n",
        "    metrics=['accuracy']  # Metric to monitor\n",
        ")\n",
        "\n",
        "# Step 18: Print the model summary\n",
        "print(\"Model Summary:\")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44vqi2mU4Ecr"
      },
      "source": [
        "# **Define Callbacks and Train the Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHvJA-1d4IDs"
      },
      "outputs": [],
      "source": [
        "# Step 19: Define callbacks for training\n",
        "epochs = 20  # Number of training epochs\n",
        "\n",
        "# Custom callback to print accuracy after each epoch\n",
        "class SaveAndPrintAccuracy(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        accuracy = logs.get('accuracy')\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        print(f\"\\nEpoch {epoch + 1}: Training Accuracy = {accuracy:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n",
        "\n",
        "# ModelCheckpoint callback to save the best model\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=os.path.join(models_folder, 'model_epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}.keras'),\n",
        "    save_freq='epoch',  # Save after each epoch\n",
        "    save_weights_only=False,  # Save the entire model\n",
        "    verbose=1  # Print messages\n",
        ")\n",
        "\n",
        "# Step 20: Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,  # Number of validation steps\n",
        "    epochs=epochs,  # Number of epochs\n",
        "    callbacks=[checkpoint_callback, SaveAndPrintAccuracy()]  # Callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb6zvwFa4KmE"
      },
      "source": [
        "# **Save and Load the Final Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o0dzmyna4L3T"
      },
      "outputs": [],
      "source": [
        "# Step 21: Save the final trained model\n",
        "final_model_path = os.path.join(models_folder, 'disease_classifier.h5')\n",
        "model.save(final_model_path)\n",
        "print(f\"Final model saved at: {final_model_path}\")\n",
        "\n",
        "# Step 22: Load the saved model\n",
        "model = load_model(final_model_path)\n",
        "print(\"Model loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTJ1rxJO4O6i"
      },
      "source": [
        "# **Prediction Function and Example Usage**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8-HmQG84SCj"
      },
      "outputs": [],
      "source": [
        "# Step 23: Function to predict the class of a new image\n",
        "def predict_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))  # Load image\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)  # Convert image to array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Normalize pixel values\n",
        "    predictions = model.predict(img_array)  # Make predictions\n",
        "    predicted_class = np.argmax(predictions, axis=1)  # Get the predicted class\n",
        "    predicted_label = label_mapping[predicted_class[0]]  # Map class index to label\n",
        "    return predicted_label\n",
        "\n",
        "# Step 24: Example usage of the prediction function\n",
        "test_image_path = os.path.join(input_folder, 'example_image.jpg')  # Replace with an actual image path\n",
        "if os.path.exists(test_image_path):\n",
        "    print(f'Predicted class: {predict_image(test_image_path)}')\n",
        "else:\n",
        "    print(f\"Test image not found at {test_image_path}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}