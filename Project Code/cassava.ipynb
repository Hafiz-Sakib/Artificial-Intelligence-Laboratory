{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Import Libraries**"
      ],
      "metadata": {
        "id": "SAoQozqB2-9X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "OF7d_Pdx3CR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mount Google Drive and Define Paths and Create Folders**"
      ],
      "metadata": {
        "id": "a0qP28lD3ECZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Step 3: Define paths for input, output, CSV, and models\n",
        "input_folder = \"/content/drive/MyDrive/Dataset/train/train_data\"  # Folder containing original images\n",
        "output_folder = \"/content/drive/MyDrive/Dataset/train/augmented_images\"  # Folder to save augmented images\n",
        "csv_folder = \"/content/drive/MyDrive/Dataset/train/other/train.csv\"  # Path to the CSV file\n",
        "models_folder = \"/content/drive/MyDrive/Dataset/train/models\"  # Folder to save trained models\n",
        "\n",
        "# Step 4: Create folders if they don't exist\n",
        "os.makedirs(output_folder, exist_ok=True)  # Create folder for augmented images\n",
        "os.makedirs(models_folder, exist_ok=True)  # Create folder for saving models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "dEh0GA493MFP",
        "outputId": "099947b6-0365-4477-a505-489c6fd5ed63"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'drive' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3b8a479202a4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'drive' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load CSV File and Add Class Names**"
      ],
      "metadata": {
        "id": "6CaP8XEu3luF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Load the CSV file containing image IDs and labels\n",
        "df = pd.read_csv(csv_folder)\n",
        "print(\"CSV file loaded successfully. First few rows:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 6: Define a mapping for labels to class names\n",
        "label_mapping = {\n",
        "    0: \"Cassava Bacterial Blight (CBB)\",\n",
        "    1: \"Cassava Brown Streak Disease (CBSD)\",\n",
        "    2: \"Cassava Green Mottle (CGM)\",\n",
        "    3: \"Cassava Mosaic Disease (CMD)\",\n",
        "    4: \"Healthy\"\n",
        "}\n",
        "\n",
        "# Step 7: Add a new column to the DataFrame for class names\n",
        "df['class_name'] = df['label'].map(label_mapping)\n",
        "print(\"DataFrame with class names added:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "_xBMR0Nj3nUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Dataset into Training and Validation Sets**"
      ],
      "metadata": {
        "id": "yP4CLH8Y3pT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Split the dataset into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "print(\"Training samples:\", len(train_df))\n",
        "print(\"Validation samples:\", len(val_df))"
      ],
      "metadata": {
        "id": "LZdLnnSO3sy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Image Dimensions and Data Augmentation**"
      ],
      "metadata": {
        "id": "eYn-SjLg3vBz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Define image dimensions and batch size\n",
        "img_height, img_width = 150, 150  # Resize images to 150x150 pixels\n",
        "batch_size = 32  # Number of images processed in each batch\n",
        "\n",
        "# Step 10: Set up data augmentation for training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
        "    rotation_range=20,  # Randomly rotate images by 20 degrees\n",
        "    width_shift_range=0.2,  # Randomly shift images horizontally by 20%\n",
        "    height_shift_range=0.2,  # Randomly shift images vertically by 20%\n",
        "    shear_range=0.2,  # Apply shear transformations\n",
        "    zoom_range=0.2,  # Randomly zoom images by 20%\n",
        "    horizontal_flip=True,  # Randomly flip images horizontally\n",
        "    fill_mode='nearest'  # Fill missing pixels with the nearest value\n",
        ")\n",
        "\n",
        "# Step 11: Only rescale validation data (no augmentation)\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "VU39Xw8c3zBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Create Data Generators**"
      ],
      "metadata": {
        "id": "4k0i1Qtj3zxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Create a training data generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,  # Training DataFrame\n",
        "    directory=input_folder,  # Folder containing images\n",
        "    x_col='image_id',  # Column with image filenames\n",
        "    y_col='label',  # Column with integer labels\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    class_mode='raw'  # Use 'raw' for integer labels\n",
        ")\n",
        "\n",
        "# Step 13: Create a validation data generator\n",
        "val_generator = val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,  # Validation DataFrame\n",
        "    directory=input_folder,  # Folder containing images\n",
        "    x_col='image_id',  # Column with image filenames\n",
        "    y_col='label',  # Column with integer labels\n",
        "    target_size=(img_height, img_width),  # Resize images\n",
        "    batch_size=batch_size,  # Batch size\n",
        "    class_mode='raw',  # Use 'raw' for integer labels\n",
        "    shuffle=False  # Do not shuffle validation data\n",
        ")"
      ],
      "metadata": {
        "id": "iKu6xhT133iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Visualize and Save Augmented Images**"
      ],
      "metadata": {
        "id": "GS6CjfP834cm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 14: Function to visualize and save augmented images in separate folders\n",
        "def visualize_and_save_augmented_images(generator, save_dir, num_images=10):\n",
        "    # Get the first batch of augmented images\n",
        "    images, labels = next(generator)\n",
        "\n",
        "    # Create a subfolder for each image and save the augmented image\n",
        "    for i in range(num_images):\n",
        "        image_folder = os.path.join(save_dir, f'augmented_image_{i + 1}')  # Create folder for each image\n",
        "        os.makedirs(image_folder, exist_ok=True)\n",
        "\n",
        "        # Save the augmented image\n",
        "        img = array_to_img(images[i])  # Convert array to image\n",
        "        img.save(os.path.join(image_folder, f'augmented_image_{i + 1}.jpg'))  # Save image\n",
        "\n",
        "        # Display the image\n",
        "        plt.figure()\n",
        "        plt.imshow(images[i])\n",
        "        plt.title(f'Label: {labels[i]}')\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "# Step 15: Call the function to visualize and save augmented images\n",
        "visualize_and_save_augmented_images(train_generator, output_folder)"
      ],
      "metadata": {
        "id": "3Imz1Gwf38GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define and Compile the Model**"
      ],
      "metadata": {
        "id": "qm57tKwI3_zT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 16: Define the CNN model architecture\n",
        "num_classes = len(label_mapping)  # Number of unique classes\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),  # First convolutional layer\n",
        "    layers.MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),  # Second convolutional layer\n",
        "    layers.MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),  # Third convolutional layer\n",
        "    layers.MaxPooling2D((2, 2)),  # Max pooling layer\n",
        "    layers.Flatten(),  # Flatten the output\n",
        "    layers.Dense(512, activation='relu'),  # Fully connected layer\n",
        "    layers.Dropout(0.5),  # Dropout layer to prevent overfitting\n",
        "    layers.Dense(num_classes, activation='softmax')  # Output layer with softmax activation\n",
        "])\n",
        "\n",
        "# Step 17: Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',  # Optimizer\n",
        "    loss='sparse_categorical_crossentropy',  # Loss function for integer labels\n",
        "    metrics=['accuracy']  # Metric to monitor\n",
        ")\n",
        "\n",
        "# Step 18: Print the model summary\n",
        "print(\"Model Summary:\")\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "INHDdgJw4CYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Callbacks and Train the Model**"
      ],
      "metadata": {
        "id": "44vqi2mU4Ecr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 19: Define callbacks for training\n",
        "epochs = 20  # Number of training epochs\n",
        "\n",
        "# Custom callback to print accuracy after each epoch\n",
        "class SaveAndPrintAccuracy(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        accuracy = logs.get('accuracy')\n",
        "        val_accuracy = logs.get('val_accuracy')\n",
        "        print(f\"\\nEpoch {epoch + 1}: Training Accuracy = {accuracy:.4f}, Validation Accuracy = {val_accuracy:.4f}\")\n",
        "\n",
        "# ModelCheckpoint callback to save the best model\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=os.path.join(models_folder, 'model_epoch_{epoch:02d}_val_acc_{val_accuracy:.4f}.keras'),\n",
        "    save_freq='epoch',  # Save after each epoch\n",
        "    save_weights_only=False,  # Save the entire model\n",
        "    verbose=1  # Print messages\n",
        ")\n",
        "\n",
        "# Step 20: Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=train_generator.samples // batch_size,  # Number of steps per epoch\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=val_generator.samples // batch_size,  # Number of validation steps\n",
        "    epochs=epochs,  # Number of epochs\n",
        "    callbacks=[checkpoint_callback, SaveAndPrintAccuracy()]  # Callbacks\n",
        ")"
      ],
      "metadata": {
        "id": "rHvJA-1d4IDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Save and Load the Final Model**"
      ],
      "metadata": {
        "id": "Gb6zvwFa4KmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 21: Save the final trained model\n",
        "final_model_path = os.path.join(models_folder, 'disease_classifier.h5')\n",
        "model.save(final_model_path)\n",
        "print(f\"Final model saved at: {final_model_path}\")\n",
        "\n",
        "# Step 22: Load the saved model\n",
        "model = load_model(final_model_path)\n",
        "print(\"Model loaded successfully.\")"
      ],
      "metadata": {
        "id": "o0dzmyna4L3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prediction Function and Example Usage**"
      ],
      "metadata": {
        "id": "GTJ1rxJO4O6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 23: Function to predict the class of a new image\n",
        "def predict_image(image_path):\n",
        "    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(img_height, img_width))  # Load image\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img)  # Convert image to array\n",
        "    img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
        "    img_array /= 255.0  # Normalize pixel values\n",
        "    predictions = model.predict(img_array)  # Make predictions\n",
        "    predicted_class = np.argmax(predictions, axis=1)  # Get the predicted class\n",
        "    predicted_label = label_mapping[predicted_class[0]]  # Map class index to label\n",
        "    return predicted_label\n",
        "\n",
        "# Step 24: Example usage of the prediction function\n",
        "test_image_path = os.path.join(input_folder, 'example_image.jpg')  # Replace with an actual image path\n",
        "if os.path.exists(test_image_path):\n",
        "    print(f'Predicted class: {predict_image(test_image_path)}')\n",
        "else:\n",
        "    print(f\"Test image not found at {test_image_path}\")"
      ],
      "metadata": {
        "id": "A8-HmQG84SCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}